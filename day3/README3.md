# 12th June Note
## 1. æ•°æ®å‡†å¤‡é˜¶æ®µ

### âœ… æ–‡ä»¶ï¼š`deal_with_datasets.py`
- **ä½œç”¨**ï¼šå°†åŸå§‹å›¾ç‰‡åˆ’åˆ†ä¸º `train/` å’Œ `val/` å­ç›®å½•ï¼ˆæŒ‰ç…§æ¯”ä¾‹éšæœºåˆ’åˆ†ï¼‰ã€‚
- **å‘½ä»¤**ï¼š
  ```bash
  python deal_with_datasets.py
  ```
- **è¾“å‡ºç»“æ„**ï¼š
  ```
  image2/train/class_x/*.jpg
  image2/val/class_x/*.jpg
  ```
- **ç”¨é€”**ï¼šä¸ºåç»­è®­ç»ƒå’ŒéªŒè¯é›†åˆ¶ä½œæ•°æ®ç›®å½•ç»“æ„ã€‚

---

### âœ… æ–‡ä»¶ï¼š`prepare.py`
- **ä½œç”¨**ï¼šç”Ÿæˆè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç´¢å¼•æ–‡ä»¶ `train.txt` å’Œ `val.txt`ï¼Œæ¯è¡ŒåŒ…å«å›¾ç‰‡ç›¸å¯¹è·¯å¾„å’Œç±»åˆ«æ ‡ç­¾ã€‚
- **å‘½ä»¤**ï¼š
  ```bash
  python prepare.py
  ```
- **è¾“å‡º**ï¼š
  ```
  train.txt / val.txt
  # æ–‡ä»¶å†…å®¹ç¤ºä¾‹ï¼š
  class1/img001.jpg 0
  class2/img045.jpg 1
  ```
- **ç”¨é€”**ï¼šä¾› PyTorch è‡ªå®šä¹‰ Dataset ç±»è¯»å–ï¼Œæ„å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚

---

## 2. æ¨¡å‹å®šä¹‰é˜¶æ®µ

### âœ… æ–‡ä»¶ï¼š`vit_model.py`
- **ä½œç”¨**ï¼šå®šä¹‰ Vision Transformer (ViT) æ¨¡å‹ç»“æ„ï¼ŒåŒ…æ‹¬ï¼š
  - `PatchEmbedding`ï¼ˆå›¾åƒåˆ‡åˆ†æˆ patchï¼‰
  - `Multi-head Attention`ï¼ˆå¤šå¤´æ³¨æ„åŠ›ï¼‰
  - `Transformer Encoder`ï¼ˆç¼–ç å™¨å †ï¼‰
  - `MLP` åˆ†ç±»å¤´
- **ç”¨é€”**ï¼šè¢« `train.py` å¯¼å…¥å¹¶å®ä¾‹åŒ–ä¸ºè®­ç»ƒæ¨¡å‹ã€‚

---

## 3. æ¨¡å‹è®­ç»ƒé˜¶æ®µ

### âœ… æ–‡ä»¶ï¼š`train.py`
- **ä½œç”¨**ï¼š
  - åŠ è½½è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆä½¿ç”¨ `train.txt` / `val.txt`ï¼‰
  - åˆå§‹åŒ– ViT æ¨¡å‹
  - æ‰§è¡Œè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹
  - è¾“å‡º Loss å’Œ Accuracy
- **å‘½ä»¤**ï¼š
  ```bash
  python train.py
  ```
- **è¾“å‡ºç¤ºä¾‹**ï¼š
  ```
  [Epoch 1] Loss: 2075.35, Accuracy: 28.53%
  Validation Accuracy: 35.67%
  ```
- **ç”¨é€”**ï¼šè®­ç»ƒ ViT æ¨¡å‹ï¼Œå¹¶è¯„ä¼°å…¶åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ã€‚

---

## ğŸ“ æ–‡ä»¶ä¸€ï¼šå›¾åƒç‰ˆ ViT å®ç°ï¼ˆä»¥ 2D å›¾åƒä¸ºè¾“å…¥ï¼‰

### ğŸ”§ æ¶æ„è¯´æ˜

#### PatchEmbedding
- åŠŸèƒ½ï¼šå°†å›¾åƒåˆ†å‰²ä¸º patch å¹¶å±•å¼€ä¸ºå‘é‡ï¼Œå†æŠ•å½±åˆ° `dim` ç»´ã€‚
- è¾“å…¥å°ºå¯¸ï¼š`[B, 3, H, W]`
- è¾“å‡ºå°ºå¯¸ï¼š`[B, N_patches, dim]`
- å®ç°æ–¹å¼ï¼š
  ```python
  Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size)
  ```

#### Attention
- åŠŸèƒ½ï¼šå®ç°å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€‚
- ç‰¹ç‚¹ï¼š
  - QKV å…¨éƒ¨ç”±ä¸€ä¸ªçº¿æ€§å±‚å¾—åˆ°ã€‚
  - ä½¿ç”¨ `einops` å¤„ç†ç»´åº¦ï¼Œå¢å¼ºå¯è¯»æ€§ã€‚

#### Transformer
- ç»„æˆï¼š
  - å¤šä¸ª encoder blockï¼ˆæ¯ä¸ªå« LayerNorm + Attention + FeedForwardï¼‰
  - æ®‹å·®è¿æ¥å’Œ LayerNorm é¡ºåºä¸æ ‡å‡† Transformer ä¸€è‡´ï¼ˆPost-LNï¼‰ã€‚

#### ViT ä¸»ç±»
- è¾“å…¥ï¼šå›¾åƒå¼ é‡ `[B, 3, 256, 256]`
- æ­¥éª¤ï¼š
  1. Patch åµŒå…¥ã€‚
  2. åŠ å…¥åˆ†ç±» token `cls_token`ã€‚
  3. åŠ ä¸Šä½ç½®ç¼–ç  `pos_embedding`ã€‚
  4. Transformer ç¼–ç ã€‚
  5. åˆ†ç±»å¤´è¾“å‡ºé¢„æµ‹ã€‚

### ğŸ§ª ç¤ºä¾‹ç”¨æ³•
```python
model = ViT(image_size=256, patch_size=16, num_classes=100, ...)
img = torch.randn(1, 3, 256, 256)
logits = model(img)  # è¾“å‡º [1, 100]
```

---

## ğŸ“ æ–‡ä»¶äºŒï¼šä¸€ç»´æ—¶é—´åºåˆ—ç‰ˆ ViT å®ç°ï¼ˆç”¨äº 1D ä¿¡å·ï¼‰

### ğŸ“Œ è¾“å…¥ç»“æ„
- è¾“å…¥ shapeï¼š`[B, C, L]`ï¼Œä¾‹å¦‚ `[4, 3, 256]`
- å°†ä¸€ç»´ä¿¡å·åˆ’åˆ†ä¸º `patch_size` é•¿åº¦çš„ç‰‡æ®µã€‚
- æ¯ä¸ª patch æ˜¯ `[patch_size Ã— C]`ï¼Œåæ¥ Linear æ˜ å°„åˆ° `dim`ã€‚

### ğŸ”§ PatchEmbeddingï¼ˆæ—¶é—´åºåˆ—ç‰ˆï¼‰
```python
Rearrange('b c (n p) -> b n (p c)', p=patch_size)
```

### ğŸ”„ åˆ†ç±» Token æ‹¼æ¥æ–¹å¼
- ç”±äºè¾“å…¥æ˜¯åºåˆ—ï¼Œåˆ†ç±» token æ˜¯ `[dim]`ï¼Œç›´æ¥é€šè¿‡ `repeat` æ‰©å±•ä¸º `[B, dim]`ã€‚
- ä½¿ç”¨ `einops.pack` å’Œ `unpack` æ¥ç»„åˆå’Œæå–åˆ†ç±» tokenã€‚

### ğŸ§  Transformer ä¸ FeedForward
ç»“æ„ä¸å›¾åƒç‰ˆæœ¬ä¸€è‡´ã€‚

### âœ… è¾“å‡º
è¿”å› `[B, num_classes]` çš„ logits é¢„æµ‹ã€‚

